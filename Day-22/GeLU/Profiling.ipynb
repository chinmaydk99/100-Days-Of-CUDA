{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Numpy"
      ],
      "metadata": {
        "id": "kUmq5VH27MfV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "v_h462Ly6nlw"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def gelu_numpy(x):\n",
        "  sqrt_2_pi = np.sqrt(2*np.pi)\n",
        "  return 0.5*x*(1 + np.tanh(sqrt_2_pi*(x+0.044715*(x**3))))"
      ],
      "metadata": {
        "id": "NkdA583P6r2P"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.linspace(-5, 5, 10)\n",
        "gelu_values = gelu_numpy(x)\n",
        "\n",
        "# Print results\n",
        "for i in range(len(x)):\n",
        "    print(f\"GELU({x[i]:.2f}) = {gelu_values[i]:.5f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldHIDpCQ7kpx",
        "outputId": "1e6e46ae-f717-43c7-a55b-cca93d0cc821"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GELU(-5.00) = -0.00000\n",
            "GELU(-3.89) = -0.00000\n",
            "GELU(-2.78) = -0.00000\n",
            "GELU(-1.67) = -0.00014\n",
            "GELU(-0.56) = -0.03115\n",
            "GELU(0.56) = 0.52441\n",
            "GELU(1.67) = 1.66653\n",
            "GELU(2.78) = 2.77778\n",
            "GELU(3.89) = 3.88889\n",
            "GELU(5.00) = 5.00000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pytorch"
      ],
      "metadata": {
        "id": "y5tbw_Wd7pYl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "1XJIIePe7trl"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gelu_torch(x):\n",
        "  sqrt_2_pi = torch.sqrt(torch.tensor(2.0*np.pi))\n",
        "  return 0.5*x*(1 + torch.tanh(sqrt_2_pi*(x+0.044715*(x**3))))"
      ],
      "metadata": {
        "id": "ZMsdAmm77k2Q"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.linspace(-5, 5, 10)\n",
        "x = torch.tensor(x, dtype=torch.float32)\n",
        "gelu_values = gelu_torch(x)\n",
        "\n",
        "# Print results\n",
        "for i in range(len(x)):\n",
        "    print(f\"GELU({x[i]:.2f}) = {gelu_values[i]:.5f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqWL1je173lw",
        "outputId": "4f8814ec-f625-4a33-eefe-244a23461cb3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GELU(-5.00) = -0.00000\n",
            "GELU(-3.89) = -0.00000\n",
            "GELU(-2.78) = -0.00000\n",
            "GELU(-1.67) = -0.00014\n",
            "GELU(-0.56) = -0.03115\n",
            "GELU(0.56) = 0.52441\n",
            "GELU(1.67) = 1.66653\n",
            "GELU(2.78) = 2.77778\n",
            "GELU(3.89) = 3.88889\n",
            "GELU(5.00) = 5.00000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avhni65i76Fe",
        "outputId": "028618f1-be3a-45aa-ddbc-f16bd813b250"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing /content\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: gelu_cuda\n",
            "  Building wheel for gelu_cuda (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gelu_cuda: filename=gelu_cuda-0.0.0-cp311-cp311-linux_x86_64.whl size=269424 sha256=c8ff57dd6b5045a417ca1ccaf062ee19fe3b8e59397a4a2dcf5e935763fba6c7\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-_n4cw4ws/wheels/01/d1/e4/ca90c6fac4331f6da6de5353843d0b67505c2bbc8768ac296e\n",
            "Successfully built gelu_cuda\n",
            "Installing collected packages: gelu_cuda\n",
            "Successfully installed gelu_cuda-0.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import gelu_cuda\n",
        "\n",
        "# âœ… Generate input tensor\n",
        "size = 10_000_000  # 10M elements\n",
        "x_cpu = np.random.randn(size).astype(np.float32)\n",
        "x_torch_cpu = torch.tensor(x_cpu, device=\"cpu\")\n",
        "x_torch_gpu = torch.tensor(x_cpu, device=\"cuda\")\n",
        "\n",
        "start = time.time()\n",
        "gelu_np = 0.5 * x_cpu * (1 + np.tanh(np.sqrt(2/np.pi) * (x_cpu + 0.044715 * x_cpu**3)))\n",
        "numpy_time = time.time() - start\n",
        "print(f\"NumPy GELU time: {numpy_time:.6f} sec\")\n",
        "\n",
        "start = time.time()\n",
        "gelu_torch_cpu = F.gelu(x_torch_cpu)\n",
        "torch_cpu_time = time.time() - start\n",
        "print(f\"PyTorch GELU (CPU) time: {torch_cpu_time:.6f} sec\")\n",
        "\n",
        "start = time.time()\n",
        "gelu_torch_cuda = F.gelu(x_torch_gpu)\n",
        "torch_cuda_time = time.time() - start\n",
        "print(f\"PyTorch GELU (CUDA) time: {torch_cuda_time:.6f} sec\")\n",
        "\n",
        "start = time.time()\n",
        "gelu_custom_cuda = gelu_cuda.gelu_cuda(x_torch_gpu)\n",
        "custom_cuda_time = time.time() - start\n",
        "print(f\"Our CUDA GELU time: {custom_cuda_time:.6f} sec\")\n",
        "\n",
        "print(f\"\\nSpeedup over NumPy: {numpy_time / custom_cuda_time:.2f}x\")\n",
        "print(f\"Speedup over Torch CPU: {torch_cpu_time / custom_cuda_time:.2f}x\")\n",
        "print(f\"Speedup over Torch CUDA: {torch_cuda_time / custom_cuda_time:.2f}x\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbWe0FWlB3Qy",
        "outputId": "f4ab755a-a335-44ec-ad69-c1b6df545481"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NumPy GELU time: 0.339315 sec\n",
            "PyTorch GELU (CPU) time: 0.076992 sec\n",
            "PyTorch GELU (CUDA) time: 0.036650 sec\n",
            "Our CUDA GELU time: 0.001127 sec\n",
            "\n",
            "Speedup over NumPy: 300.95x\n",
            "Speedup over Torch CPU: 68.29x\n",
            "Speedup over Torch CUDA: 32.51x\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x63OGyJwFaBG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}