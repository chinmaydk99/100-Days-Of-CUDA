{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import triton\n",
        "import triton.language as tl\n",
        "import torch"
      ],
      "metadata": {
        "id": "ugKHrr6yTDMx"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@triton.jit\n",
        "def swizzle_tile(pid,\n",
        "    m, n,\n",
        "    block_m : tl.constexpr,\n",
        "    block_n : tl.constexpr,\n",
        "    group_m : tl.constexpr):\n",
        "\n",
        "    total_groups_m = tl.cdiv(m, block_m)\n",
        "    total_groups_n = tl.cdiv(n, block_n)\n",
        "\n",
        "    num_groups_per_block = group_m * total_groups_n\n",
        "    group_id = pid // num_groups_per_block\n",
        "\n",
        "    group_size = min(group_m , total_groups_m - group_id * group_m)\n",
        "\n",
        "    pid_m = group_id * group_m + (pid % group_size)\n",
        "    pid_n = (pid % num_groups_per_block) // group_size\n",
        "\n",
        "    return pid_m, pid_n"
      ],
      "metadata": {
        "id": "fnkPDS0Z1pQA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@triton.jit\n",
        "def splitk_gptq_kernel(\n",
        "    a_ptr, b_ptr, c_ptr, scales_ptr, zeros_ptr,\n",
        "    m, n, k,\n",
        "    stride_am, stride_ak,\n",
        "    stride_bk, stride_bn,\n",
        "    stride_cm, stride_cn,\n",
        "    stride_scales_g, stride_scales_n,\n",
        "    stride_zeros_g, stride_zeros_n,\n",
        "    groupsize,\n",
        "    BLOCK_SIZE_M: tl.constexpr,\n",
        "    BLOCK_SIZE_N: tl.constexpr,\n",
        "    BLOCK_SIZE_K: tl.constexpr,\n",
        "    SPLIT_K: tl.constexpr,\n",
        "    GROUP_SIZE_M: tl.constexpr\n",
        "):\n",
        "    # Program ID for processing the M and N dimensions\n",
        "    pid_mn = tl.program_id(0)\n",
        "    pid_m, pid_n = swizzle_tile(pid_mn, m, n, BLOCK_SIZE_M, BLOCK_SIZE_N, GROUP_SIZE_M)\n",
        "\n",
        "    # Program ID for processing the K dimension (split-K)\n",
        "    pid_k = tl.program_id(1)\n",
        "    total_blocks_k = tl.cdiv(k, BLOCK_SIZE_K * SPLIT_K)\n",
        "\n",
        "    # Calculate offsets for accessing matrices\n",
        "    offsets_m = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\n",
        "    offsets_n = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n",
        "    offsets_k = pid_k * BLOCK_SIZE_K + tl.arange(0, BLOCK_SIZE_K)\n",
        "\n",
        "    # Ensure coalesced memory access\n",
        "    offsets_am = tl.max_contiguous(tl.multiple_of(offsets_m, BLOCK_SIZE_M), BLOCK_SIZE_M)\n",
        "    offsets_bn = tl.max_contiguous(tl.multiple_of(offsets_n, BLOCK_SIZE_N), BLOCK_SIZE_N)\n",
        "\n",
        "    # Compute pointers to input matrices\n",
        "    a_ptrs = a_ptr + offsets_am[:, None] * stride_am + offsets_k[None, :] * stride_ak\n",
        "    b_ptrs = b_ptr + (offsets_k[:, None] // 8) * stride_bk + offsets_bn[None, :] * stride_bn\n",
        "\n",
        "    # Compute pointers to scales and zeros\n",
        "    scales_ptrs = scales_ptr + offsets_n * stride_scales_n\n",
        "    zeros_ptrs = zeros_ptr + (offsets_n // 8) * stride_zeros_n\n",
        "\n",
        "    # Compute bit shifters for 4-bit values\n",
        "    shifter = (offsets_k % 8) * 4\n",
        "    zeros_shifter = (offsets_n % 8) * 4\n",
        "\n",
        "    # Initialize accumulator\n",
        "    acc = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)\n",
        "\n",
        "    # Main loop over K dimension\n",
        "    for k_idx in range(total_blocks_k):\n",
        "        # Load inputs\n",
        "        a = tl.load(a_ptrs)\n",
        "        b_quant = tl.load(b_ptrs)\n",
        "\n",
        "        # Quantization group id\n",
        "        g_id = (k_idx * SPLIT_K + pid_k) * BLOCK_SIZE_K // groupsize\n",
        "\n",
        "        # Load scales and zeros for current group\n",
        "        group_scale_ptr = scales_ptrs + g_id * stride_scales_g\n",
        "        scales = tl.load(group_scale_ptr)\n",
        "\n",
        "        group_zero_ptr = zeros_ptrs + g_id * stride_zeros_g\n",
        "        zeros = tl.load(group_zero_ptr)\n",
        "\n",
        "        # Extract and dequantize 4-bit weights\n",
        "        zeros = (zeros >> zeros_shifter) & 0xF\n",
        "        zeros = (zeros + 1) * scales\n",
        "\n",
        "        b = (b_quant >> shifter[:, None]) & 0xF\n",
        "        b = b * scales[None, :] - zeros[None, :]\n",
        "\n",
        "        # Compute dot product and accumulate\n",
        "        acc += tl.dot(a, b)\n",
        "\n",
        "        # Move pointers for next iteration\n",
        "        a_ptrs += BLOCK_SIZE_K * SPLIT_K * stride_ak\n",
        "        b_ptrs += (BLOCK_SIZE_K // 8) * SPLIT_K * stride_bk\n",
        "\n",
        "    # Convert accumulator to float16 (if needed)\n",
        "    acc = acc.to(tl.float16)\n",
        "\n",
        "    # Calculate output pointers\n",
        "    c_ptrs = c_ptr + offsets_m[:, None] * stride_cm + offsets_n[None, :] * stride_cn\n",
        "\n",
        "    # Atomic add for split-K reduction\n",
        "    tl.atomic_add(c_ptrs, acc)"
      ],
      "metadata": {
        "id": "aL5Z_JBv2p8B"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SplitK_GPTQLinear(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, a, b, scales, zeros, groupsize=128):\n",
        "        M, K = a.shape\n",
        "        _, N = b.shape\n",
        "\n",
        "        # Block sizes and parallelization parameters\n",
        "        BLOCK_SIZE_M = 16\n",
        "        BLOCK_SIZE_N = 32\n",
        "        BLOCK_SIZE_K = 64\n",
        "        GROUP_SIZE_M = 8\n",
        "        SPLIT_K = 4\n",
        "\n",
        "        # Calculate grid dimensions\n",
        "        total_blocks_m = triton.cdiv(M, BLOCK_SIZE_M)\n",
        "        total_blocks_n = triton.cdiv(N, BLOCK_SIZE_N)\n",
        "        total_programs = total_blocks_m * total_blocks_n\n",
        "        grid = (total_programs, SPLIT_K)\n",
        "\n",
        "        # Initialize output tensor\n",
        "        c = torch.zeros((M, N), dtype=a.dtype, device=a.device)\n",
        "\n",
        "        # Launch kernel\n",
        "        splitk_gptq_kernel[grid](\n",
        "            a, b, c,\n",
        "            scales, zeros,\n",
        "            M, N, K,\n",
        "            a.stride(0), a.stride(1),\n",
        "            b.stride(0), b.stride(1),\n",
        "            c.stride(0), c.stride(1),\n",
        "            scales.stride(0), scales.stride(1),\n",
        "            zeros.stride(0), zeros.stride(1),\n",
        "            groupsize,\n",
        "            BLOCK_SIZE_M=BLOCK_SIZE_M,\n",
        "            BLOCK_SIZE_N=BLOCK_SIZE_N,\n",
        "            BLOCK_SIZE_K=BLOCK_SIZE_K,\n",
        "            GROUP_SIZE_M=GROUP_SIZE_M,\n",
        "            SPLIT_K=SPLIT_K\n",
        "        )\n",
        "\n",
        "        return c\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        # Backward not implemented yet\n",
        "        return None, None, None, None, None\n",
        "\n",
        "def splitk_gptq_linear(a, b, scales, zeros, groupsize=128):\n",
        "    return SplitK_GPTQLinear.apply(a, b, scales, zeros, groupsize)"
      ],
      "metadata": {
        "id": "uFgQytFRAyoV"
      },
      "execution_count": 4,
      "outputs": []
    }
  ]
}